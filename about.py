from py2neo import Graph
import torch
import torch.nn as nn
import torch.optim as optim
import random
from torch_geometric.nn import GraphSAGE
from torch_geometric.data import Data
import re

# ðŸ”— Káº¿t ná»‘i Ä‘áº¿n Neo4j
NEO4J_URI = "neo4j+s://fa2fd127.databases.neo4j.io"
NEO4J_USER = "neo4j"
NEO4J_PASSWORD = "k6y0bLBbHmLw5g-lopuQFKvIsEvjyTig7Y2r-p7aPOc"

try:
    graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
    print("âœ… Káº¿t ná»‘i Neo4j thÃ nh cÃ´ng!")
except Exception as e:
    print(f"âŒ Lá»—i káº¿t ná»‘i Neo4j: {e}")
    exit()

# ðŸ“Œ TrÃ­ch xuáº¥t dá»¯ liá»‡u tá»« Neo4j
query = """
MATCH (e:Employee)-[:HAS_ABOUT]->(a:About)
RETURN id(e) AS source, id(a) AS target, e.name AS employee_name, a.type AS about_text
"""
result = graph.run(query).to_data_frame()

if result.empty:
    print("âš  KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u quan há»‡ Employee-About")
    exit()
else:
    print(result)

# ðŸ“Œ Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u sang tensor
edge_index = torch.tensor(result[['source', 'target']].values, dtype=torch.long).t().contiguous()
n_nodes = max(edge_index.flatten()).item() + 1
x = torch.randn(n_nodes, 128)  # Random feature vector cho má»—i node
data = Data(x=x, edge_index=edge_index)

# ðŸ“Œ Táº¡o tá»« Ä‘iá»ƒn Ã¡nh xáº¡ ID -> TÃªn thá»±c thá»ƒ
id_to_name = {row['source']: row['employee_name'] for _, row in result.iterrows()}
id_to_name.update({row['target']: row['about_text'] for _, row in result.iterrows()})

# ðŸ“Œ Sinh negative samples
positive_edges = edge_index.t().tolist()
all_nodes = set(range(n_nodes))
negative_edges = []

while len(negative_edges) < len(positive_edges):
    src, tgt = random.sample(sorted(all_nodes), 2)
    if [src, tgt] not in positive_edges:
        negative_edges.append([src, tgt])

y = torch.cat([torch.ones(len(positive_edges)), torch.zeros(len(negative_edges))])
edge_index = torch.tensor(positive_edges + negative_edges, dtype=torch.long).t().contiguous()
data.edge_index = edge_index


# ðŸ“Œ HÃ m tÃ­nh toÃ¡n Ä‘á»™ tin cáº­y cá»§a quan há»‡
def calculate_confidence(prediction_score, entity_text, about_text):
    # Tham sá»‘ trá»ng sá»‘
    alpha = 0.2  # Trá»ng sá»‘ cho Ä‘iá»ƒm dá»± Ä‘oÃ¡n tá»« GraphSAGE
    beta = 0.4  # Trá»ng sá»‘ cho Ä‘á»™ cá»¥ thá»ƒ cá»§a entity
    gamma = 0.4  # Trá»ng sá»‘ cho ngá»¯ cáº£nh

    # Äo lÆ°á»ng Ä‘á»™ cá»¥ thá»ƒ (specificity) cá»§a entity
    # CÃ ng dÃ i vÃ  chi tiáº¿t cÃ ng cá»¥ thá»ƒ
    specificity_score = min(1.0, len(entity_text.split()) / 10)

    # Äo lÆ°á»ng cháº¥t lÆ°á»£ng ngá»¯ cáº£nh xung quanh entity
    # TÃ¬m vá»‹ trÃ­ cá»§a entity trong about_text
    try:
        entity_pos = about_text.find(entity_text)
        if entity_pos >= 0:
            # Láº¥y 20 kÃ½ tá»± trÆ°á»›c vÃ  sau entity Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ ngá»¯ cáº£nh
            start = max(0, entity_pos - 20)
            end = min(len(about_text), entity_pos + len(entity_text) + 20)
            context = about_text[start:end]

            # ÄÃ¡nh giÃ¡ ngá»¯ cáº£nh dá»±a trÃªn sá»‘ tá»« khÃ³a quan trá»ng xuáº¥t hiá»‡n
            context_keywords = ["experience", "expert", "skill", "proficient",
                                "knowledge", "worked", "years", "project",
                                "expertise"]
            keyword_count = sum(1 for keyword in context_keywords if
                                keyword.lower() in context.lower())
            context_score = min(1.0, keyword_count / 3)
        else:
            context_score = 0.0
    except:
        context_score = 0.0

    # TÃ­nh tá»•ng Ä‘iá»ƒm tin cáº­y theo cÃ´ng thá»©c
    confidence = alpha * prediction_score + beta * specificity_score + gamma * context_score

    return confidence, {
        "prediction": prediction_score,
        "specificity": specificity_score,
        "context": context_score
    }

# ðŸ“Œ Äá»‹nh nghÄ©a mÃ´ hÃ¬nh GraphSAGE
class LinkPredictor(nn.Module):
    def __init__(self, in_channels, hidden_channels):
        super().__init__()
        self.sage = GraphSAGE(in_channels, hidden_channels, num_layers=2)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_channels * 2, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

    def forward(self, data):
        x = self.sage(data.x, data.edge_index)
        edge_embeds = torch.cat([x[data.edge_index[0]], x[data.edge_index[1]]], dim=1)
        return self.mlp(edge_embeds).squeeze()

# ðŸ“Œ Huáº¥n luyá»‡n mÃ´ hÃ¬nh
model = LinkPredictor(in_channels=128, hidden_channels=256)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = nn.BCEWithLogitsLoss()

for epoch in range(100):
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, y)
    loss.backward()
    optimizer.step()
    if epoch % 10 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item()}")

# ðŸ“Œ Dá»± Ä‘oÃ¡n quan há»‡ áº©n
with torch.no_grad():
    predictions = torch.sigmoid(model(data))
    predicted_edges = edge_index[:, predictions > 0.7].t().tolist()

# ðŸ“Œ HÃ m trÃ­ch xuáº¥t thÃ´ng tin tá»« About
def extract_entities(about_text):
    skills = []
    projects = []
    expertise = []

    # TÃ¬m "years of experience" (HAS_SKILL)
    exp_skills = re.findall(r'(\d+ years of experience in [\w\s]+)', about_text)
    skills.extend(exp_skills)

    # TÃ¬m "Expert in ..." hoáº·c "Experienced in ..." (EXPERTISE)
    expert_exp = re.findall(r'(Expert in [\w\s]+|Experienced in [\w\s]+)', about_text)
    expertise.extend(expert_exp)

    # Náº¿u cÃ³ tá»« "worked on" â†’ PROJECT
    worked_projects = re.findall(r'(worked on [\w\s]+)', about_text)
    projects.extend(worked_projects)

    return {
        "skills": skills,
        "projects": projects,
        "expertise": expertise
    }


# ðŸ“Œ Hiá»ƒn thá»‹ quan há»‡ rÃµ rÃ ng hÆ¡n
print("\nðŸ” Quan há»‡ áº©n má»›i Ä‘Æ°á»£c phÃ¡t hiá»‡n:")
if not predicted_edges:
    print("âš  KhÃ´ng tÃ¬m tháº¥y quan há»‡ áº©n nÃ o")
else:
    for idx, (src, tgt) in enumerate(predicted_edges):
        src_name = id_to_name.get(src, f"Node {src}")
        tgt_name = id_to_name.get(tgt, f"Node {tgt}")

        # Láº¥y Ä‘iá»ƒm dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh
        pred_score = predictions[idx].item()

        # Kiá»ƒm tra náº¿u About lÃ  None hoáº·c rá»—ng
        if tgt_name is None or tgt_name.strip() == "":
            print(f"âš  {src_name} -> KhÃ´ng cÃ³ thÃ´ng tin tá»« About (Bá»Ž QUA)")
            continue  # Bá» qua quan há»‡ nÃ y

        # Náº¿u About lÃ  má»™t Ä‘oáº¡n text, trÃ­ch xuáº¥t thá»±c thá»ƒ
        entities = extract_entities(tgt_name)
        if entities["skills"] or entities["projects"] or entities["expertise"]:
            for skill in entities["skills"]:
                confidence, details = calculate_confidence(pred_score, skill,
                                                           tgt_name)
                if confidence > 0.6:  # Chá»‰ giá»¯ láº¡i cÃ¡c quan há»‡ cÃ³ Ä‘á»™ tin cáº­y cao
                    print(
                        f"ðŸ› ï¸ {src_name} -> {skill} (HAS_DETAIL_EXPERIENCE) [Confidence: {confidence:.2f}]")

            for project in entities["projects"]:
                confidence, details = calculate_confidence(pred_score, project,
                                                           tgt_name)
                if confidence > 0.6:
                    print(
                        f"ðŸ› ï¸ {src_name} -> {project} (WORKED_ON) [Confidence: {confidence:.2f}]")

            for exp in entities["expertise"]:
                confidence, details = calculate_confidence(pred_score, exp,
                                                           tgt_name)
                if confidence > 0.6:
                    print(
                        f"ðŸ› ï¸ {src_name} -> {exp} (EXPERTISE) [Confidence: {confidence:.2f}]")
        else:
            print(f"âš  {src_name} -> KhÃ´ng tÃ¬m tháº¥y thá»±c thá»ƒ nÃ o (Bá»Ž QUA)")

# 7ï¸âƒ£ Cáº­p nháº­t quan há»‡ vÃ o Neo4j
if predicted_edges:
    print("\nðŸ“¡ Cáº­p nháº­t vÃ o Neo4j...")
    for idx, (src, tgt) in enumerate(predicted_edges):
        src_name = id_to_name.get(src, f"Node {src}")
        tgt_name = id_to_name.get(tgt, f"Node {tgt}")
        pred_score = predictions[idx].item()

        # Náº¿u About lÃ  None hoáº·c rá»—ng, bá» qua
        if tgt_name is None or tgt_name.strip() == "":
            continue

        # TrÃ­ch xuáº¥t thá»±c thá»ƒ tá»« About
        entities = extract_entities(tgt_name)
        relationships = []

        if entities["skills"]:
            for skill in entities["skills"]:
                confidence, _ = calculate_confidence(pred_score, skill,
                                                     tgt_name)
                if confidence > 0.6:
                    relationships.append(
                        (src_name, "HAS_DETAIL_EXPERIENCE", skill, confidence))

        if entities["projects"]:
            for project in entities["projects"]:
                confidence, _ = calculate_confidence(pred_score, project,
                                                     tgt_name)
                if confidence > 0.6:
                    relationships.append(
                        (src_name, "WORKED_ON", project, confidence))

        if entities["expertise"]:
            for exp in entities["expertise"]:
                confidence, _ = calculate_confidence(pred_score, exp, tgt_name)
                if confidence > 0.6:
                    relationships.append(
                        (src_name, "EXPERTISE", exp, confidence))

        # ChÃ¨n vÃ o Neo4j
        for (source, relation, target, conf) in relationships:
            cypher_query = f"""
            MERGE (e:Employee {{name: '{source}'}})
            MERGE (t:Detail_Exp {{name: '{target}'}})
            MERGE (e)-[r:{relation}]->(t)
            SET r.confidence = {conf}
            """
            graph.run(cypher_query)
            print(
                f"âœ… {source} -[:{relation} (conf:{conf:.2f})]-> {target} Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o Neo4j")

    print("ðŸŽ¯ Cáº­p nháº­t hoÃ n táº¥t!")
else:
    print("âš  KhÃ´ng cÃ³ quan há»‡ má»›i Ä‘á»ƒ cáº­p nháº­t.")