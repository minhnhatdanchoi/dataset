import torch
import torch.nn as nn
import torch.optim as optim
import random
import re
from py2neo import Graph
from neo4j import GraphDatabase
from torch_geometric.nn import GraphSAGE
from torch_geometric.data import Data

# Nháº­p cáº¥u hÃ¬nh vÃ  cáº¥u trÃºc dá»¯ liá»‡u tá»« cÃ¡c tá»‡p riÃªng biá»‡t
from config import (
    NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD,
    MODEL_PARAMS, TRAINING_PARAMS,
    CONFIDENCE_THRESHOLDS, CONFIDENCE_WEIGHTS
)
from entity_patterns import ENTITY_PATTERNS
from context_keywords import CONTEXT_KEYWORDS

# ============================
# Káº¿t ná»‘i Neo4j
# ============================
def connect_to_neo4j():
    """Thiáº¿t láº­p káº¿t ná»‘i Ä‘áº¿n cÆ¡ sá»Ÿ dá»¯ liá»‡u Neo4j."""
    try:
        graph = Graph(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        print("âœ… Káº¿t ná»‘i Neo4j thÃ nh cÃ´ng!")
        return graph
    except Exception as e:
        print(f"âŒ Lá»—i káº¿t ná»‘i Neo4j: {e}")
        exit()

# ============================
# TrÃ­ch xuáº¥t dá»¯ liá»‡u
# ============================
def extract_data_from_neo4j(graph):
    """TrÃ­ch xuáº¥t dá»¯ liá»‡u node vÃ  má»‘i quan há»‡ tá»« Neo4j."""
    # Query Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c má»‘i quan há»‡ hiá»‡n cÃ³
    query = """
    MATCH (e:Employee)-[r]->(n)
    WHERE type(r) <> 'HAS_ABOUT' AND any(label IN labels(n) WHERE label IN ['Nationality', 'Language', 'Project', 'Technology', 'Seniority'])
    RETURN id(e) AS source, id(n) AS target, e.name AS employee_name, labels(n)[0] AS node_type, n.name AS node_name, type(r) AS relationship_type
    UNION
    MATCH (e:Employee)-[:HAS_ABOUT]->(a:About)
    RETURN id(e) AS source, id(a) AS target, e.name AS employee_name, 'About' AS node_type, a.type AS node_name, 'HAS_ABOUT' AS relationship_type
    """
    result = graph.run(query).to_data_frame()

    if result.empty:
        print("âš  KhÃ´ng tÃ¬m tháº¥y má»‘i quan há»‡ Employee-About nÃ o")
        exit()
    else:
        print(f"TÃ¬m tháº¥y {len(result)} má»‘i quan há»‡")

    return result

def extract_existing_technology_relationships(graph):
    """Truy váº¥n riÃªng cÃ¡c má»‘i quan há»‡ giá»¯a nhÃ¢n viÃªn vÃ  cÃ´ng nghá»‡ (Technology)."""
    query = """
    MATCH (e:Employee)-[r]->(t:Technology)
    RETURN e.name AS employee_name, t.name AS technology_name, type(r) AS relationship_type
    """
    existing_tech_relationships = graph.run(query).to_data_frame()

    # Táº¡o tá»« Ä‘iá»ƒn Ä‘á»ƒ theo dÃµi cÃ¡c má»‘i quan há»‡ cÃ´ng nghá»‡ hiá»‡n cÃ³ cho má»—i nhÃ¢n viÃªn
    employee_tech_relationships = {}
    if not existing_tech_relationships.empty:
        for _, row in existing_tech_relationships.iterrows():
            employee = row['employee_name']
            tech = row['technology_name']
            if employee not in employee_tech_relationships:
                employee_tech_relationships[employee] = set()
            employee_tech_relationships[employee].add(tech.lower())

        print(f"TÃ¬m tháº¥y má»‘i quan há»‡ cÃ´ng nghá»‡ hiá»‡n cÃ³ cho {len(employee_tech_relationships)} nhÃ¢n viÃªn")
    else:
        print("KhÃ´ng tÃ¬m tháº¥y má»‘i quan há»‡ cÃ´ng nghá»‡ nÃ o")

    return employee_tech_relationships

# ============================
# XÃ¢y dá»±ng Ä‘á»“ thá»‹
# ============================
def prepare_graph_data(result):

    # Chuyá»ƒn Ä‘á»•i thÃ nh tensor
    edge_index = torch.tensor(result[['source', 'target']].values,
                              dtype=torch.long).t().contiguous()
    n_nodes = max(edge_index.flatten()).item() + 1
    x = torch.randn(n_nodes, 64)  # Vector Ä‘áº·c trÆ°ng ngáº«u nhiÃªn cho má»—i node
    data = Data(x=x, edge_index=edge_index)

    # Táº¡o tá»« Ä‘iá»ƒn id_to_info Ä‘á»ƒ Ã¡nh xáº¡ ID node trong Ä‘á»“ thá»‹ sang thÃ´ng tin thá»±c thá»ƒ
    # LÆ°u thÃ´ng tin tÃªn vÃ  loáº¡i cho má»—i node
    id_to_info = {}
    for _, row in result.iterrows():
        id_to_info[row['source']] = {'name': row['employee_name'], 'type': 'Employee'}
        id_to_info[row['target']] = {'name': row['node_name'],'type': row['node_type']}

    # Táº¡o cÃ¡c máº«u Ã¢m (negative samples)
    positive_edges = edge_index.t().tolist()
    all_nodes = set(range(n_nodes))
    negative_edges = []

    while len(negative_edges) < len(positive_edges):
        src, tgt = random.sample(sorted(all_nodes), 2)
        if [src, tgt] not in positive_edges:
            negative_edges.append([src, tgt])

    y = torch.cat(
        [torch.ones(len(positive_edges)), torch.zeros(len(negative_edges))])
    train_edge_index = torch.tensor(positive_edges + negative_edges,
                                    dtype=torch.long).t().contiguous()

    return data, train_edge_index, y, id_to_info

# ============================
# Äá»‹nh nghÄ©a mÃ´ hÃ¬nh
# ============================
class LinkPredictor(nn.Module):
    def __init__(self, in_channels, hidden_channels, num_layers=2, dropout=0.2):
        """
        Tham sá»‘:
            in_channels: Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o
            hidden_channels: Sá»‘ lÆ°á»£ng Ä‘áº·c trÆ°ng áº©n
            num_layers: Sá»‘ lá»›p GraphSAGE
            dropout: Tá»· lá»‡ dropout
        """
        super().__init__()
        self.sage = GraphSAGE(in_channels, hidden_channels, num_layers=num_layers, dropout=dropout)
        self.mlp = nn.Sequential(
            nn.Linear(hidden_channels * 2, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 1)
        )

    def forward(self, x, edge_index):
        """Táº¡o biá»ƒu diá»…n node."""
        x = self.sage(x, edge_index)
        return x

    def predict_links(self, x, edge_index_to_predict):
        """Dá»± Ä‘oÃ¡n kháº£ nÄƒng tá»“n táº¡i liÃªn káº¿t giá»¯a cÃ¡c cáº·p node."""
        edge_embeds = torch.cat(
            [x[edge_index_to_predict[0]], x[edge_index_to_predict[1]]], dim=1)
        return self.mlp(edge_embeds).squeeze()

# ============================
# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
# ============================
def train_model(model, data, train_edge_index, train_y, epochs=100, lr=0.01, print_interval=10):
    """Huáº¥n luyá»‡n mÃ´ hÃ¬nh LinkPredictor."""
    optimizer = optim.Adam(model.parameters(), lr=lr)
    criterion = nn.BCEWithLogitsLoss()

    print("\nðŸ”„ Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh GraphSAGE...")
    for epoch in range(epochs):
        optimizer.zero_grad()
        node_embeddings = model(data.x, data.edge_index)
        output = model.predict_links(node_embeddings, train_edge_index)
        loss = criterion(output, train_y)
        loss.backward()
        optimizer.step()
        if epoch % print_interval == 0:
            print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

    return model

# ============================
# TrÃ­ch xuáº¥t thá»±c thá»ƒ
# ============================
def extract_entities(about_text, entity_types=None):
    """
    TrÃ­ch xuáº¥t thá»±c thá»ƒ tá»« vÄƒn báº£n About dá»±a trÃªn cÃ¡c loáº¡i thá»±c thá»ƒ Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh.

    Tham sá»‘:
        about_text: VÄƒn báº£n Ä‘á»ƒ trÃ­ch xuáº¥t thá»±c thá»ƒ
        entity_types: Danh sÃ¡ch cÃ¡c loáº¡i thá»±c thá»ƒ cáº§n trÃ­ch xuáº¥t

    Tráº£ vá»:
        Tá»« Ä‘iá»ƒn cÃ¡c thá»±c thá»ƒ Ä‘Ã£ trÃ­ch xuáº¥t theo loáº¡i
    """
    if entity_types is None:
        entity_types = ENTITY_PATTERNS.keys()

    entities = {entity_type: [] for entity_type in entity_types}

    # Xá»­ lÃ½ tá»«ng cÃ¢u riÃªng biá»‡t Ä‘á»ƒ cÃ³ ngá»¯ cáº£nh tá»‘t hÆ¡n
    sentences = re.split(r'[.;]', about_text)  # TÃ¡ch báº±ng dáº¥u cháº¥m vÃ  cháº¥m pháº©y
    sentences = [s.strip() for s in sentences if s.strip()]

    # Ãp dá»¥ng máº«u cho tá»«ng cÃ¢u vÃ  loáº¡i thá»±c thá»ƒ Ä‘Æ°á»£c yÃªu cáº§u
    for sentence in sentences:
        for entity_type in entity_types:
            if entity_type in ENTITY_PATTERNS:
                for pattern in ENTITY_PATTERNS[entity_type]:
                    matches = re.findall(pattern, sentence, re.IGNORECASE)
                    if matches:
                        # TrÃ­ch xuáº¥t tá»«ng thá»±c thá»ƒ tá»« danh sÃ¡ch Ä‘Æ°á»£c phÃ¢n tÃ¡ch bá»Ÿi dáº¥u pháº©y
                        for match in matches:
                            if isinstance(match, tuple):  # Äá»‘i vá»›i cÃ¡c nhÃ³m regex
                                match = match[0]  # Láº¥y nhÃ³m Ä‘áº§u tiÃªn

                            # Xá»­ lÃ½ danh sÃ¡ch thá»±c thá»ƒ Ä‘Æ°á»£c phÃ¢n tÃ¡ch báº±ng dáº¥u pháº©y
                            if ',' in match:
                                # Náº¿u lÃ  danh sÃ¡ch phÃ¢n tÃ¡ch báº±ng dáº¥u pháº©y, tÃ¡ch vÃ  xá»­ lÃ½ tá»«ng má»¥c
                                split_entities = [m.strip() for m in re.split(r',\s*', match)]
                                for split_entity in split_entities:
                                    # Kiá»ƒm tra láº¡i tá»«ng thá»±c thá»ƒ Ä‘Æ°á»£c tÃ¡ch vá»›i máº«u
                                    if re.search(pattern, split_entity, re.IGNORECASE):
                                        entities[entity_type].append(split_entity)
                            else:
                                entities[entity_type].append(match.strip())

    # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho Experience_Level Ä‘á»ƒ trÃ­ch xuáº¥t thá»i gian vÃ  cÃ´ng nghá»‡ liÃªn quan
    if 'Experience_Level' in entity_types and entities['Experience_Level']:
        refined_experiences = []
        for exp in entities['Experience_Level']:
            # TrÃ­ch xuáº¥t sá»‘ nÄƒm
            duration_pattern = r'(\d+\+?)\s*years?'
            duration_match = re.search(duration_pattern, exp, re.IGNORECASE)
            if duration_match:
                duration = duration_match.group(1)

                # Cá»‘ gáº¯ng trÃ­ch xuáº¥t cÃ´ng nghá»‡/lÄ©nh vá»±c mÃ  kinh nghiá»‡m liÃªn quan Ä‘áº¿n
                tech_pattern = r'experience\s+(?:in|with|of)\s+([\w\s,\.\-]+)'
                tech_match = re.search(tech_pattern, exp, re.IGNORECASE)

                # Náº¿u khÃ´ng khá»›p vá»›i máº«u tiÃªu chuáº©n, thá»­ máº«u thay tháº¿
                if not tech_match:
                    tech_pattern = r'experience\s+(?:in|with|of)\s+the\s+([\w\s,\.\-]+)'
                    tech_match = re.search(tech_pattern, exp, re.IGNORECASE)

                if tech_match:
                    tech = tech_match.group(1).strip()
                    # LÃ m sáº¡ch chuá»—i cÃ´ng nghá»‡
                    tech = re.sub(r'[,\.]$', '', tech).strip()
                    refined_experiences.append(f"{duration} years in {tech}")
                else:
                    refined_experiences.append(f"{duration} years")

        entities['Experience_Level'] = refined_experiences

    # LÃ m sáº¡ch thá»±c thá»ƒ (loáº¡i bá» trÃ¹ng láº·p, cáº¯t ngáº¯n cÃ¡c má»¥c dÃ i)
    for entity_type in entity_types:
        entities[entity_type] = list(set(entities[entity_type]))
        # Cáº¯t ngáº¯n cÃ¡c thá»±c thá»ƒ dÃ i
        entities[entity_type] = [entity[:100] if len(entity) > 100 else entity
                               for entity in entities[entity_type]]

    return entities

def calculate_confidence(prediction_score, entity_text, about_text, entity_type):
    """
    TÃ­nh toÃ¡n Ä‘iá»ƒm tin cáº­y cho má»™t thá»±c thá»ƒ Ä‘Æ°á»£c trÃ­ch xuáº¥t dá»±a trÃªn nhiá»u yáº¿u tá»‘.

    Tham sá»‘:
        prediction_score: Äiá»ƒm tá»« mÃ´ hÃ¬nh GraphSAGE
        entity_text: VÄƒn báº£n thá»±c thá»ƒ Ä‘Æ°á»£c trÃ­ch xuáº¥t
        about_text: VÄƒn báº£n gá»‘c mÃ  thá»±c thá»ƒ Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« Ä‘Ã³
        entity_type: Loáº¡i cá»§a thá»±c thá»ƒ

    Tráº£ vá»:
        Tuple cá»§a (Ä‘iá»ƒm_tin_cáº­y, tá»«_Ä‘iá»ƒn_chi_tiáº¿t)
    """
    # Láº¥y trá»ng sá»‘ dá»±a trÃªn loáº¡i thá»±c thá»ƒ
    weights = CONFIDENCE_WEIGHTS.get(entity_type, CONFIDENCE_WEIGHTS['default'])
    alpha = weights['prediction']  # Trá»ng sá»‘ cho dá»± Ä‘oÃ¡n GraphSAGE
    beta = weights['specificity']  # Trá»ng sá»‘ cho tÃ­nh cá»¥ thá»ƒ cá»§a thá»±c thá»ƒ
    gamma = weights['context']     # Trá»ng sá»‘ cho cháº¥t lÆ°á»£ng ngá»¯ cáº£nh

    # Äo lÆ°á»ng tÃ­nh cá»¥ thá»ƒ cá»§a thá»±c thá»ƒ (dÃ i hÆ¡n vÃ  chi tiáº¿t hÆ¡n thÃ¬ tá»‘t hÆ¡n)
    specificity_score = min(1.0, len(entity_text.split()) / 10)

    # Äiá»ƒm ngá»¯ cáº£nh máº·c Ä‘á»‹nh
    context_score = 0.0

    # TÃ¬m vá»‹ trÃ­ thá»±c thá»ƒ trong vÄƒn báº£n about
    entity_pos = about_text.lower().find(entity_text.lower())
    if entity_pos >= 0:
        # Láº¥y ngá»¯ cáº£nh xung quanh thá»±c thá»ƒ
        start = max(0, entity_pos - 30)
        end = min(len(about_text), entity_pos + len(entity_text) + 30)
        context = about_text[start:end]

        # Láº¥y tá»« khÃ³a thÃ­ch há»£p cho loáº¡i thá»±c thá»ƒ nÃ y
        keywords = CONTEXT_KEYWORDS.get(entity_type,
                                       ["experience", "skill", "worked", "knowledge", "years"])

        # Äáº¿m sá»‘ láº§n xuáº¥t hiá»‡n tá»« khÃ³a trong ngá»¯ cáº£nh
        keyword_count = sum(
            1 for keyword in keywords if keyword.lower() in context.lower())
        context_score = min(1.0, keyword_count / 3)

    # TÃ­nh toÃ¡n tá»•ng Ä‘á»™ tin cáº­y
    confidence = alpha * prediction_score + beta * specificity_score + gamma * context_score

    return confidence, {
        "prediction": prediction_score,
        "specificity": specificity_score,
        "context": context_score
    }

def determine_relationship_type(source_type, target_type):
    """
    XÃ¡c Ä‘á»‹nh loáº¡i má»‘i quan há»‡ dá»±a trÃªn loáº¡i node nguá»“n vÃ  Ä‘Ã­ch.

    Tham sá»‘:
        source_type: Loáº¡i cá»§a node nguá»“n
        target_type: Loáº¡i cá»§a node Ä‘Ã­ch

    Tráº£ vá»:
        Chuá»—i Ä‘áº¡i diá»‡n cho loáº¡i má»‘i quan há»‡
    """
    if source_type == 'Employee':
        if target_type == 'Skill':
            return 'HAS_DETAIL_SKILL'
        elif target_type == 'Technology':
            return 'HAS_TECHNOLOGY'
        elif target_type == 'Experience_Level':
            return 'HAS_EXPERIENCE_LEVEL'
        elif target_type == 'Project':
            return 'WORKED_ON'
        elif target_type == 'Industry':
            return 'HAS_INDUSTRY_EXPERIENCE'
        elif target_type == 'Soft_Skill':
            return 'HAS_SOFT_SKILL'

    # TrÆ°á»ng há»£p máº·c Ä‘á»‹nh
    return 'RELATED_TO'

def create_temp_entity_embedding(entity_text, entity_type, node_embeddings, id_to_info):
    """
    Táº¡o má»™t biá»ƒu diá»…n táº¡m thá»i cho má»™t thá»±c thá»ƒ má»›i dá»±a trÃªn cÃ¡c thá»±c thá»ƒ tÆ°Æ¡ng tá»± trong Ä‘á»“ thá»‹.

    Tham sá»‘:
        entity_text: VÄƒn báº£n cá»§a thá»±c thá»ƒ má»›i
        entity_type: Loáº¡i cá»§a thá»±c thá»ƒ (Technology, Skill, v.v.)
        node_embeddings: Biá»ƒu diá»…n node hiá»‡n táº¡i tá»« mÃ´ hÃ¬nh
        id_to_info: Tá»« Ä‘iá»ƒn Ã¡nh xáº¡ ID node sang thÃ´ng tin node

    Tráº£ vá»:
        Má»™t tensor biá»ƒu diá»…n cho thá»±c thá»ƒ má»›i
    """
    # TÃ¬m cÃ¡c node hiá»‡n cÃ³ cÃ¹ng loáº¡i Ä‘á»ƒ sá»­ dá»¥ng lÃ m tham chiáº¿u
    similar_nodes = []

    # Láº¥y ID cá»§a cÃ¡c node hiá»‡n cÃ³ cÃ¹ng loáº¡i
    for node_id, info in id_to_info.items():
        if info['type'] == entity_type:
            # TÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vÄƒn báº£n (Ä‘Æ¡n giáº£n lÃ  sá»± trÃ¹ng láº·p tá»«)
            entity_words = set(entity_text.lower().split())
            node_words = set(info['name'].lower().split())

            # TÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
            if len(entity_words) > 0 and len(node_words) > 0:
                intersection = len(entity_words.intersection(node_words))
                union = len(entity_words.union(node_words))
                similarity = intersection / union if union > 0 else 0

                similar_nodes.append((node_id, similarity))

    # Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (cao nháº¥t trÆ°á»›c)
    similar_nodes.sort(key=lambda x: x[1], reverse=True)

    # Náº¿u cÃ³ node tÆ°Æ¡ng tá»±, sá»­ dá»¥ng trung bÃ¬nh cÃ³ trá»ng sá»‘ cá»§a top 3 lÃ m biá»ƒu diá»…n
    if similar_nodes:
        # Láº¥y top 3 hoáº·c nhiá»u nháº¥t cÃ³ thá»ƒ
        top_nodes = similar_nodes[:min(3, len(similar_nodes))]

        # Náº¿u khÃ´ng cÃ³ node tÆ°Æ¡ng tá»± nÃ o cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng > 0, sá»­ dá»¥ng biá»ƒu diá»…n ngáº«u nhiÃªn
        if sum(sim for _, sim in top_nodes) == 0:
            return torch.randn(node_embeddings.shape[1])

        # TÃ­nh trung bÃ¬nh cÃ³ trá»ng sá»‘ biá»ƒu diá»…n
        weighted_sum = torch.zeros(node_embeddings.shape[1])
        total_weight = 0

        for node_id, similarity in top_nodes:
            if similarity > 0:
                weighted_sum += node_embeddings[node_id] * similarity
                total_weight += similarity

        if total_weight > 0:
            return weighted_sum / total_weight

    # PhÆ°Æ¡ng Ã¡n dá»± phÃ²ng: Tráº£ vá» má»™t biá»ƒu diá»…n ngáº«u nhiÃªn thiÃªn vá» trung bÃ¬nh cá»§a táº¥t cáº£ cÃ¡c thá»±c thá»ƒ cÃ¹ng loáº¡i
    type_embeddings = [node_embeddings[node_id] for node_id, info in
                      id_to_info.items()
                      if info['type'] == entity_type]

    if type_embeddings:
        # Tráº£ vá» biá»ƒu diá»…n ngáº«u nhiÃªn thiÃªn vá» trung bÃ¬nh cá»§a loáº¡i nÃ y
        avg_embedding = torch.stack(type_embeddings).mean(dim=0)
        random_factor = 0.3
        return avg_embedding * (1 - random_factor) + torch.randn_like(
            avg_embedding) * random_factor

    # PhÆ°Æ¡ng Ã¡n cuá»‘i cÃ¹ng: biá»ƒu diá»…n hoÃ n toÃ n ngáº«u nhiÃªn
    return torch.randn(node_embeddings.shape[1])

def get_existing_technology_node(graph, technology_name):
    """
    Kiá»ƒm tra xem má»™t node cÃ´ng nghá»‡ vá»›i tÃªn Ä‘Ã£ cho cÃ³ tá»“n táº¡i trong cÆ¡ sá»Ÿ dá»¯ liá»‡u hay khÃ´ng.

    Tham sá»‘:
        graph: Káº¿t ná»‘i Ä‘á»“ thá»‹ Neo4j
        technology_name: TÃªn cá»§a cÃ´ng nghá»‡ cáº§n kiá»ƒm tra

    Tráº£ vá»:
        Boolean cho biáº¿t node cÃ³ tá»“n táº¡i hay khÃ´ng
    """
    query = """
    MATCH (t:Technology {name: $tech_name})
    RETURN count(t) > 0 AS exists
    """
    result = graph.evaluate(query, tech_name=technology_name)
    return result

# ============================
# HÃ m xá»­ lÃ½ chÃ­nh
# ============================
def process_about_texts(graph, result, node_embeddings, model, id_to_info, employee_tech_relationships):
    """
    Xá»­ lÃ½ cÃ¡c node About vÃ  trÃ­ch xuáº¥t thá»±c thá»ƒ.

    Tham sá»‘:
        graph: Káº¿t ná»‘i Ä‘á»“ thá»‹ Neo4j
        result: DataFrame chá»©a dá»¯ liá»‡u Ä‘á»“ thá»‹
        node_embeddings: Biá»ƒu diá»…n node tá»« mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
        model: MÃ´ hÃ¬nh LinkPredictor Ä‘Ã£ huáº¥n luyá»‡n
        id_to_info: Tá»« Ä‘iá»ƒn Ã¡nh xáº¡ ID node sang thÃ´ng tin node
        employee_tech_relationships: Tá»« Ä‘iá»ƒn theo dÃµi cÃ¡c má»‘i quan há»‡ cÃ´ng nghá»‡ hiá»‡n cÃ³

    Tráº£ vá»:
        Thá»‘ng kÃª vá» cÃ¡c thá»±c thá»ƒ vÃ  má»‘i quan há»‡ Ä‘Ã£ trÃ­ch xuáº¥t
    """
    print("\nðŸ” Äang xá»­ lÃ½ cÃ¡c node About vÃ  trÃ­ch xuáº¥t thá»±c thá»ƒ...")
    employees_with_about = result[result['node_type'] == 'About']

    # Bá»™ Ä‘áº¿m
    total_hidden_nodes_found = 0
    total_hidden_relationships_found = 0
    hidden_nodes_by_type = {
        'Technology': 0,
        'Skill': 0,
        'Soft_Skill': 0,
        'Experience_Level': 0,
        'Project': 0
    }
    hidden_relationships_by_type = {
        'HAS_TECHNOLOGY': 0,
        'HAS_DETAIL_SKILL': 0,
        'HAS_SOFT_SKILL': 0,
        'HAS_EXPERIENCE_LEVEL': 0,
        'WORKED_ON': 0
    }

    for _, row in employees_with_about.iterrows():
        employee_id = row['source']
        about_id = row['target']
        employee_name = row['employee_name']
        about_text = row['node_name']

        # Bá» qua náº¿u vÄƒn báº£n About trá»‘ng
        if about_text is None or about_text.strip() == "":
            print(f"âš  {employee_name} cÃ³ vÄƒn báº£n About trá»‘ng (Bá»Ž QUA)")
            continue

        print(f"\nðŸ“‘ Äang xá»­ lÃ½ vÄƒn báº£n About cho {employee_name}:")

        # TrÃ­ch xuáº¥t thá»±c thá»ƒ tá»« vÄƒn báº£n About
        entity_types = ['Skill', 'Technology', 'Experience_Level', 'Project',
                        'Soft_Skill']
        extracted_entities = extract_entities(about_text, entity_types)

        # Xá»­ lÃ½ tá»«ng loáº¡i thá»±c thá»ƒ
        new_relationships = []

        for entity_type, entities in extracted_entities.items():
            if not entities:
                continue

            print(f"  TÃ¬m tháº¥y {len(entities)} thá»±c thá»ƒ {entity_type}")

            for entity in entities:
                # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho thá»±c thá»ƒ Technology - KIá»‚M TRA Má»I QUAN Há»† HIá»†N CÃ“
                if entity_type == 'Technology':
                    # Chuyá»ƒn Ä‘á»•i thÃ nh chá»¯ thÆ°á»ng Ä‘á»ƒ so sÃ¡nh khÃ´ng phÃ¢n biá»‡t chá»¯ hoa/thÆ°á»ng
                    entity_lower = entity.lower()

                    # Kiá»ƒm tra xem nhÃ¢n viÃªn Ä‘Ã£ cÃ³ má»‘i quan há»‡ vá»›i cÃ´ng nghá»‡ nÃ y chÆ°a (báº¥t ká»ƒ loáº¡i má»‘i quan há»‡)
                    if employee_name in employee_tech_relationships and entity_lower in employee_tech_relationships[
                        employee_name]:
                        print(f"  â© Bá» qua {entity}: {employee_name} Ä‘Ã£ cÃ³ má»‘i quan há»‡ vá»›i cÃ´ng nghá»‡ nÃ y")
                        continue

                # Táº¡o biá»ƒu diá»…n táº¡m thá»i cho thá»±c thá»ƒ má»›i
                temp_entity_embedding = create_temp_entity_embedding(entity, entity_type,
                                                                     node_embeddings, id_to_info)

                # Láº¥y biá»ƒu diá»…n cá»§a nhÃ¢n viÃªn
                employee_embedding = node_embeddings[employee_id]

                # TÃ­nh Ä‘iá»ƒm dá»± Ä‘oÃ¡n sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
                # Ná»‘i biá»ƒu diá»…n cá»§a nhÃ¢n viÃªn vÃ  thá»±c thá»ƒ
                edge_embedding = torch.cat([employee_embedding, temp_entity_embedding],
                                           dim=0).unsqueeze(0)

                # Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ dá»± Ä‘oÃ¡n xÃ¡c suáº¥t liÃªn káº¿t
                with torch.no_grad():
                    prediction_score_tensor = torch.sigmoid(
                        model.mlp(edge_embedding).squeeze())
                    prediction_score = prediction_score_tensor.item()

                # TÃ­nh toÃ¡n Ä‘á»™ tin cáº­y tá»•ng thá»ƒ
                confidence, details = calculate_confidence(
                    prediction_score, entity, about_text, entity_type
                )

                threshold = CONFIDENCE_THRESHOLDS.get(entity_type, 0.6)
                # Chá»‰ giá»¯ láº¡i cÃ¡c má»‘i quan há»‡ cÃ³ Ä‘á»™ tin cáº­y cao hÆ¡n ngÆ°á»¡ng
                if confidence > threshold:
                    relationship_type = determine_relationship_type('Employee', entity_type)
                    new_relationships.append({
                        'employee_name': employee_name,
                        'entity': entity,
                        'entity_type': entity_type,
                        'relationship_type': relationship_type,
                        'confidence': confidence,
                        'prediction_score': prediction_score,
                        'context_score': details['context'],
                        'specificity_score': details['specificity']
                    })

                    print(
                        f"  ðŸ”„ {entity_type}: {entity[:50]}{'...' if len(entity) > 50 else ''} [Conf: {confidence:.2f}, Pred: {prediction_score:.2f}]")

        # ThÃªm má»‘i quan há»‡ vÃ o Neo4j
        for rel in new_relationships:
            # Äá»‘i vá»›i thá»±c thá»ƒ Technology, trÆ°á»›c tiÃªn kiá»ƒm tra xem node Ä‘Ã£ tá»“n táº¡i chÆ°a
            node_exists = False
            if rel['entity_type'] == 'Technology':
                node_exists = get_existing_technology_node(graph, rel['entity'])
            else:
                # Kiá»ƒm tra xem node Ä‘Ã£ tá»“n táº¡i chÆ°a Ä‘á»‘i vá»›i cÃ¡c loáº¡i thá»±c thá»ƒ khÃ¡c
                check_node_query = f"""
          MATCH (n:{rel['entity_type']} {{name: $name}})
          RETURN count(n) > 0 AS exists
          """
                node_exists = graph.evaluate(check_node_query, name=rel['entity'])

            # Táº¡o truy váº¥n Cypher Ä‘á»ƒ thÃªm má»‘i quan há»‡
            # Sá»­ dá»¥ng MERGE cho cáº£ node vÃ  má»‘i quan há»‡ Ä‘á»ƒ Ä‘áº£m báº£o chÃºng tá»“n táº¡i mÃ  khÃ´ng bá»‹ trÃ¹ng láº·p
            cypher_query = f"""
                MATCH (e:Employee {{name: $employee_name}})
                MERGE (t:{rel['entity_type']} {{name: $entity_name}})
                MERGE (e)-[r:{rel['relationship_type']}]->(t)
                SET r.confidence = $confidence,
                    r.prediction_score = $prediction_score,
                    r.context_score = $context_score,
                    r.specificity_score = $specificity_score,
                    r.extracted_from = 'about_text'
                """

            # Thá»±c thi truy váº¥n
            try:
                graph.run(
                    cypher_query,
                    employee_name=rel['employee_name'],
                    entity_name=rel['entity'],
                    confidence=rel['confidence'],
                    prediction_score=rel['prediction_score'],
                    context_score=rel['context_score'],
                    specificity_score=rel['specificity_score']
                )

                # Cáº­p nháº­t bá»™ Ä‘áº¿m thá»‘ng kÃª
                total_hidden_relationships_found += 1
                hidden_relationships_by_type[rel['relationship_type']] = hidden_relationships_by_type.get(
                    rel['relationship_type'], 0) + 1

                if not node_exists:
                    total_hidden_nodes_found += 1
                    hidden_nodes_by_type[rel['entity_type']] = hidden_nodes_by_type.get(rel['entity_type'], 0) + 1

                # ThÃ´ng bÃ¡o khÃ¡c nhau tÃ¹y thuá»™c vÃ o viá»‡c node Ä‘Ã£ tá»“n táº¡i trÆ°á»›c Ä‘Ã³ hay chÆ°a
                if node_exists:
                    print(
                        f"  âœ… ÄÃ£ thÃªm má»‘i quan há»‡ Ä‘áº¿n node hiá»‡n cÃ³: {rel['employee_name']} -[:{rel['relationship_type']} ({rel['confidence']:.2f})]-> {rel['entity_type']}:{rel['entity'][:30]}..."
                    )
                else:
                    print(
                        f"  âœ… ÄÃ£ thÃªm node vÃ  má»‘i quan há»‡ má»›i: {rel['employee_name']} -[:{rel['relationship_type']} ({rel['confidence']:.2f})]-> {rel['entity_type']}:{rel['entity'][:30]}..."
                    )

                # Náº¿u Ä‘Ã¢y lÃ  thá»±c thá»ƒ Technology, cáº­p nháº­t theo dÃµi trong bá»™ nhá»›
                if rel['entity_type'] == 'Technology':
                    if rel['employee_name'] not in employee_tech_relationships:
                        employee_tech_relationships[rel['employee_name']] = set()
                    employee_tech_relationships[rel['employee_name']].add(rel['entity'].lower())

            except Exception as e:
                print(f"  âŒ Lá»—i khi thÃªm má»‘i quan há»‡: {e}")

    # Tráº£ vá» thá»‘ng kÃª
    return {
        'total_hidden_nodes': total_hidden_nodes_found,
        'total_hidden_relationships': total_hidden_relationships_found,
        'hidden_nodes_by_type': hidden_nodes_by_type,
        'hidden_relationships_by_type': hidden_relationships_by_type
    }

def print_summary_statistics(stats):
    """In thá»‘ng kÃª tÃ³m táº¯t cá»§a quÃ¡ trÃ¬nh trÃ­ch xuáº¥t."""
    print("\nðŸ“Š THá»NG KÃŠ TÃ“M Táº®T:")
    print(f"Tá»•ng sá»‘ node áº©n Ä‘Æ°á»£c phÃ¡t hiá»‡n: {stats['total_hidden_nodes']}")
    print(f"Tá»•ng sá»‘ má»‘i quan há»‡ áº©n Ä‘Æ°á»£c phÃ¡t hiá»‡n: {stats['total_hidden_relationships']}")

    if stats['total_hidden_nodes'] > 0:
        print("\nNode áº©n theo loáº¡i:")
        for node_type, count in stats['hidden_nodes_by_type'].items():
            if count > 0:
                print(f"  - {node_type}: {count}")

    if stats['total_hidden_relationships'] > 0:
        print("\nMá»‘i quan há»‡ áº©n theo loáº¡i:")
        for rel_type, count in stats['hidden_relationships_by_type'].items():
            if count > 0:
                print(f"  - {rel_type}: {count}")


def main():
    # Káº¿t ná»‘i Ä‘áº¿n Neo4j
    graph = connect_to_neo4j()

    # TrÃ­ch xuáº¥t dá»¯ liá»‡u
    result = extract_data_from_neo4j(graph)
    employee_tech_relationships = extract_existing_technology_relationships(graph)

    # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»“ thá»‹
    data, train_edge_index, train_y, id_to_info = prepare_graph_data(result)

    # Khá»Ÿi táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh
    model = LinkPredictor(
        in_channels=MODEL_PARAMS['in_channels'],
        hidden_channels=MODEL_PARAMS['hidden_channels'],
        num_layers=MODEL_PARAMS['num_layers'],
        dropout=MODEL_PARAMS['dropout']
    )

    model = train_model(
        model, data, train_edge_index, train_y,
        epochs=TRAINING_PARAMS['epochs'],
        lr=TRAINING_PARAMS['learning_rate'],
        print_interval=TRAINING_PARAMS['print_interval']
    )

    # Láº¥y biá»ƒu diá»…n node tá»« mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n
    with torch.no_grad():
        node_embeddings = model(data.x, data.edge_index)

    # Xá»­ lÃ½ vÄƒn báº£n About
    stats = process_about_texts(
        graph, result, node_embeddings, model,
        id_to_info, employee_tech_relationships
    )


    print_summary_statistics(stats)

    print("\nðŸŽ¯ Xá»­ lÃ½ hoÃ n táº¥t!")

if __name__ == "__main__":
    main()